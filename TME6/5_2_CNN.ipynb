{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TME 5.2 : Convolutional Neural Network\n",
        "\n",
        "\n",
        "## Recherche de pattern (motifs) en utilisant les modèles d'apprentissage profond\n",
        "\n",
        "Nous allons utiliser l'algorithme Deep Learning Convolutional Neural Network pour la recherche de motifs. \n",
        "Notre objectif est de construire un classifieur capable de prédire si une séquence particulière contient le motif d'intérêt."
      ],
      "metadata": {
        "id": "kZ4C6ycPO5V4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Préparation de données\n",
        "\n",
        "1.1 Comme dans le TME précédent nous allons d'abord générer des données artificielles, un jeu de données de séquences ayant le motif (positives = label 1) et un jeu de données de séquences aléatoires (négatives = label 0). Pour générer les séquences positives, utilisez la matrice de fréquence du motif d'intérêt, par exemple, Atf1 ci-dessous.Nous allons générer 1000 séquences positives et 1000 séquences négatives. "
      ],
      "metadata": {
        "id": "G8w7E3QAR6Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#>AFT1 à remplacer par la matrice du motif d'interet\n",
        "freq = np.array([\n",
        "[106,155,362,179,426,136,716,145,34,160,10,961,8,25,19,181,265,287,276,123,154],\n",
        "[205,249,197,396,231,78,25,31,47,10,966,9,972,955,740,257,252,155,180,225,236],\n",
        "[231,220,221,222,154,142,31,288,39,812,11,15,9,2,13,494,241,183,68,357,458],\n",
        "[456,374,218,200,187,641,226,535,878,16,10,14,10,16,225,65,240,373,474,292,150]\n",
        "])\n",
        "\n",
        "motif_length = 21 # à remplacer par taille de la matrice du motif d'interet\n",
        "num_sample = 1000"
      ],
      "metadata": {
        "id": "vxjxynlxSfcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createArtSequences(freq, num_sample=100):\n",
        "  \"\"\"\n",
        "  Genere deux jeux de sequences: positives (ayant le motif) et negatives (aleatoires)\n",
        "  entrée PWM : matrice de poids position qui represent le motif d'interet\n",
        "  entrée num_sample : int, nombre d'echantillons\n",
        "  sortie pos : list contenant les sequences positives\n",
        "  sortie neg : list contenant les sequences negatives\n",
        "  \"\"\"\n",
        " \n",
        "  return pos, neg\n",
        "\n",
        "pos, neg  = createArtSequences(freq, num_sample)\n",
        "[''.join(x) for x in pos[1:10,:]]\n",
        "[''.join(x) for x in neg[1:10,:]]\n",
        "\n",
        "\n",
        "#genere y dans le format attendu numpy array (num_sample*2, 2)\n",
        "#premiere colonne correspond à la prob d'etre positive et deuxiemme d'etre negative\n",
        "s = (num_sample, 2)\n",
        "y = np.concatenate((np.zeros(s), np.zeros(s)))\n",
        "count = 0\n",
        "for i in range(len(y)):\n",
        "  if count < num_sample:\n",
        "    y[i,0] = 1\n",
        "  else:\n",
        "    y[i,1] = 1\n",
        "  count+=1\n",
        "\n",
        "print(y.shape)\n",
        "input_labels = y\n",
        "\n",
        "print (input_labels[0]) #positive\n",
        "print (input_labels[-2])#negative\n",
        "\n",
        "print (input_labels.shape)\n",
        "sequencesPos =  [''.join(x) for x in pos]\n",
        "sequencesNeg =  [''.join(x) for x in neg]\n",
        "\n",
        "sequences = sequencesPos + sequencesNeg\n",
        "print(type(sequences))\n"
      ],
      "metadata": {
        "id": "kkjTWDWKs60v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. L'étape suivante consiste à organiser les données dans un format qui peut être transmis à un algorithme d'apprentissage profond. \n",
        "La plupart des algorithmes d'apprentissage profond acceptent les données sous forme de vecteurs ou de matrices \n",
        "(ou plus généralement de tenseurs).\n",
        "\n",
        "Pour obtenir chaque séquence d'ADN sous la forme d'une matrice, nous utilisons une codage (One hot encoding), \n",
        "qui code chaque base d'une séquence sous la forme d'un vecteur à 4 dimensions, avec une dimension distincte pour chaque base. \n",
        "Nous plaçons un \"1\" dans la dimension correspondant à la base trouvée dans la séquence d'ADN, et des \"0\" dans tous les autres emplacements. \n",
        "Nous concaténant ensuite ces vecteurs à 4 dimensions le long des bases de la séquence pour former une matrice.\n",
        "\n",
        "\n",
        "Exemple\n",
        "-----------------------\n",
        "DNA Sequence #1: CCGA\n",
        "<br>\n",
        "One hot encoding de #1:\n",
        "```\n",
        " [[0. 0. 0. 1]\n",
        " [1. 1. 0. 0]\n",
        " [0. 0. 1. 0]\n",
        " [0. 0. 0  0]]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "nI35hLHnTqD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faire une fonction pour encoder les sequences d'ADN en utilisant l'One hot encoding "
      ],
      "metadata": {
        "id": "KPmNw5iYTqK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(seq):\n",
        "    \"\"\"\n",
        "    entrée seq: sequence d'ADN\n",
        "    sortie oneHot: numpy array (tmotif_length x 4)\n",
        "    \"\"\"\n",
        "    mapping = dict(zip(\"ACGT\", range(4)))    \n",
        "    seq2 = [mapping[i] for i in seq]\n",
        "    return np.eye(4)[seq2]\n",
        "\n",
        "print (one_hot_encode('AC'))\n",
        "#[[1. 0. 0. 0.]\n",
        "# [0. 1. 0. 0.]]"
      ],
      "metadata": {
        "id": "JNPvE43iA5T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faire une fonction pour générer la matrice que représente les données d'entrée d'un CNNs"
      ],
      "metadata": {
        "id": "m0JPdJvdVjT5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJD6PuDnaS6"
      },
      "source": [
        "\n",
        "def encode_sequences(sequences):\n",
        "  \"\"\"\n",
        "    entrée sequences: list de sequences d'entrainement\n",
        "    soirtie input_features: numpy array (numSamples x motif_length x 4)\n",
        "  \"\"\"\n",
        "\n",
        "  input_features = []\n",
        "\n",
        " \n",
        "\n",
        "  return np.stack(input_features)\n",
        "\n",
        "input_features = encode_sequences(sequences)\n",
        "print (input_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3. Nous divisons également les données en deux jeux, l'un pour l'entraînement et l'autre pour le test. L'objectif du jeu de test est de pouvoir mesurer la performance du modèle sur de nouvelles données, qui n'ont pas été vues auparavant pendant l'entraînement. Plus tard, nous diviserons à nouveau le jeu d'entraînement pour avoir deux jeux pour avoir aussi des données de validation."
      ],
      "metadata": {
        "id": "8OvNcog9MhqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print (input_features.shape)\n",
        "print(input_labels.shape)\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(input_features, input_labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "J6ADrsQ9Nj6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Select the Architecture and Train\n"
      ],
      "metadata": {
        "id": "HGqwce-GN0VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/abidlabs/deep-learning-genomics-primer/blob/master/Screenshot%20from%202018-08-01%2020-31-49.png?raw=true)"
      ],
      "metadata": {
        "id": "3ZZzVBCUO_o8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 - Nous allons  choisir un simple réseau neuronal convolutionnel 2D (CNN), couramment utilisé dans l'apprentissage profond pour les applications en bioinformatique.\n",
        "\n",
        "Nous utiliserons la bibliothèque d'apprentissage profond Keras. Il nous suffit de spécifier les types de couches que nous souhaitons inclure dans notre réseau, ainsi que la dimensionnalité de chaque couche. Le CNN que nous générons dans cet exercice se compose des couches suivantes :\n",
        "\n",
        " - Conv2D : nous définissons notre couche convolutive comme ayant 32 filtres (nodes) de taille 3x3 (kenel_size).\n",
        "\n",
        " - Conv2D : une autre couche convolutive comme ayant 64 filtres (nodes) de taille 3x3 (kenel_size), fonction d'activation=\"relu\".\n",
        "\n",
        " - MaxPooling2D : après la convolution, nous utilisons une couche de pooling pour réduire l'échantillonnage des sorties convolutifs. Bien que cela ne soit pas toujours nécessaire, il s'agit d'une forme typique de sous-échantillonnage non linéaire utilisée dans les CNN. Notre pool_size sera 2x2\n",
        "\n",
        " - Aplatir (Flatten) : Cette couche aplatit la sortie de la couche precedent.\n",
        "\n",
        "- Dense : La première couche Dense crée comprime la représentation de la couche aplatie, ce qui donne une couche plus petite avec 16 tenseurs (function d'activation relu, et la deuxième couche Dense fait converger les tenseurs vers la couche de sortie (dense_2) qui se compose des deux valeurs de réponse possibles (0 ou 1)."
      ],
      "metadata": {
        "id": "EW_3eiQbPgcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model2 = Sequential()\n",
        "#add Conv2,  32 filters, kenel=3\n",
        "#add Conv2,  64 filters, kenel=3, activation=\"relu\")\n",
        "#add MaxPooling2D, poolsize (2x2)\n",
        "#add Flatten\n",
        "\n",
        "#add dense 16 nodes  activation='relu'\n",
        "\n",
        "#add dense 2 nodes  activation='softmax'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "Tej8MKndhnp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Nous sommes maintenant prêts à entraîner le réseau CNN. \n",
        "Nous allons diviser le jeu de données d'entraînement en jeux de données d'entraînement et un jeu de validation. \n",
        "Nous n'effectuerons l'entraînement que sur l'ensemble de d'entraînement réduit, \n",
        "mais nous tracerons la courbe d'erreur en utilisant les deux jeux de données de formation et de validation. \n",
        "Lorsque la perte de l'ensemble de validation cesse de s'améliorer ou s'aggraver tout au long des cycles d'apprentissage, \n",
        "il est temps d'arrêter l'entraînement, car le modèle a déjà convergé."
      ],
      "metadata": {
        "id": "l0G0emgPQb8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print (train_features.shape)\n",
        "print (train_labels.shape)\n"
      ],
      "metadata": {
        "id": "x_DFSeDNVvPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model2.fit(train_features, train_labels, epochs=50, verbose=0, validation_split=0.25)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nBOYV3JC1qFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 De même, nous pouvons représenter la précision de notre réseau CNN pour la tâche de classification binaire. \n",
        "La mesure utilisée dans cet exemple est la précision binaire, qui calcule la proportion de prédictions correspondant aux étiquettes \n",
        "ou aux variables de réponse. D'autres mesures peuvent être utilisées dans différentes tâches, par exemple, l'erreur quadratique moyenne est généralement utilisée pour mesurer la précision "
      ],
      "metadata": {
        "id": "_vyj_lTMWQ8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K-oZntfYWSmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Evaluation"
      ],
      "metadata": {
        "id": "14aFBhuAWe4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/abidlabs/deep-learning-genomics-primer/blob/master/Screenshot%20from%202018-08-01%2020-32-12.png?raw=true)"
      ],
      "metadata": {
        "id": "k1jVNAJyWkRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 - La meilleure façon d'évaluer si le réseau a appris à classer les séquences est d'évaluer ses performances sur un nouvel ensemble de test composé de données qu'il n'a pas du tout observées pendant l'entraînement. Nous évaluons ici le modèle sur l'ensemble de test et présentons les résultats sous la forme d'une matrice de confusion. Presque toutes les séquences testées devraient être correctement classées."
      ],
      "metadata": {
        "id": "l7u461CNXAuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "predicted_labels = model2.predict(np.stack(test_features))\n",
        "cm = confusion_matrix(np.argmax(test_labels, axis=1), \n",
        "                      np.argmax(predicted_labels, axis=1))\n",
        "print('Confusion matrix:\\n',cm)\n",
        "\n",
        "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
        "\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.title('Normalized confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('True label')\n",
        "plt.ylabel('Predicted label')\n",
        "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
        "plt.grid('off')\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], '.2f'), horizontalalignment='center', color='white' if cm[i, j] > 0.5 else 'black')"
      ],
      "metadata": {
        "id": "06Cv9hXNWpX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWspe3oabF8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Application sur vos données"
      ],
      "metadata": {
        "id": "D_nEFnRTXUQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez entraîner un réseau CNN pour reconnaître un motif d'intérêt. Par exemple le Mac1 qui figure sur la liste \"Tablemotifs-Etudiants.pdf\". Pour cela, nous avons téléchargé la matrice de fréquence de Mac1 du site JASÄR https://jaspar.genereg.net/matrix/MA0326.1/\n",
        "Vous pouvez entraîner un réseau CNN pour reconnaître un motif d'intérêt. Par exemple le Mac1 qui figure sur la liste \"Tablemotifs-Etudiants.pdf\". Pour cela, nous avons téléchargé la matrice de fréquence de Mac1 du site\n",
        "Et procéder comme avant pour générer les données d'entraînement, validation et test.Une fois le modèle entraîné vous pouvez le tester sur vous séquences et vérifier combien de fois vous avez trouvé le motif d'intérêt sur vous données. Si le nombre d'occurrence est supérieur au hasard vous avez de forte chance que le motif d'intérêt soit représenté dans vos données. Vous pouvez répéter l'expérience pour plusieurs motifs\n",
        " d'intérêt et montrer le(s) quel(s) est(sont) le(s) plus probable."
      ],
      "metadata": {
        "id": "7jf2xjaLXVI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "motif_length = 18\n",
        "num_sample = 1000\n",
        "\n",
        "# PFM from JASPAR\n",
        "motif = np.array([[   0,   2, 104, 104,   1,   2, 103, 102,   0,   0,  99, 105,   0,   0, 100, 102,   5,   3],\n",
        "                  [   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   4,   0,   0,   2,   3,   0,   0,   3],\n",
        "                  [ 105, 103,   1,   1, 104, 102,   2,   3, 104, 103,   2,   0, 105, 103,   0,   2,  97,  97],\n",
        "                  [   0,   0,   0,   0,   0,   1,   0,   0,   1,   0,   0,   0,   0,   0,   2,   1,   3,   2]])\n"
      ],
      "metadata": {
        "id": "HePoT5EBX75m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readFasta(genome):\n",
        "    sequence = []\n",
        "    file = open(genome, \"r\")\n",
        "    sequences = []\n",
        "    seq = \"\"\n",
        "    for s in file:\n",
        "        if s[0] != \">\":\n",
        "            seq += s.strip().upper()\n",
        "        else:\n",
        "            sequences.append(seq)\n",
        "            seq = \"\"\n",
        "    return sequences[1:]\n",
        "genome = \"Sequence_by_Peaks_1.fasta\"\n",
        "sequence = readFasta(genome)[0]\n",
        "print(sequence)"
      ],
      "metadata": {
        "id": "yX68QHf8gEDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Rhp_LGMbHGe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}